{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the FARA data as a Pandas DataFrame\n",
    "filepath = \"\"\"../input-data/2019 Food Access Research Atlas Data/Food Access Research Atlas.csv\"\"\"\n",
    "data = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the FARA data to the state of Texas\n",
    "texas = data.loc[data[\"State\"]==\"Texas\",:]\n",
    "\n",
    "# Select only the relevant columns\n",
    "texas = texas[['CensusTract','State','County','Urban','Pop2010','OHU2010','LILATracts_1And10','LILATracts_halfAnd10','HUNVFlag','LowIncomeTracts',\n",
    "'PovertyRate','MedianFamilyIncome','LA1and10','LAhalfand10','LATracts_half','LALOWI1_10','LALOWI05_10','lahunvhalf','lahunvhalfshare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open McDonald's JSON file\n",
    "json_file = open(\"../input-data/mcdata.json\")\n",
    "mcdonalds = json.load(json_file)[\"features\"]\n",
    "\n",
    "# Store all the McDonalds in Texas\n",
    "mcdonalds_tx = [store for store in mcdonalds if store['properties']['state']=='TX']\n",
    "\n",
    "# Store lats and lons of each McDonald's restaurant in US\n",
    "lats = [store['geometry']['coordinates'][1] for store in mcdonalds_tx]\n",
    "lons = [store['geometry']['coordinates'][0] for store in mcdonalds_tx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the base URL - this API takes geographical coordinates and returns the Census Tract that those coordinates fall into\n",
    "base_url = \"https://geo.fcc.gov/api/census/area?\"\n",
    "\n",
    "# Initialize an empty list to store the census tract info for each store\n",
    "census_tracts = []\n",
    "\n",
    "# Loop through the stores in texas using enumerate\n",
    "for i in range(len(mcdonalds_tx)):\n",
    "\n",
    "    # create a url for each store using the latitude and longitutde and base\n",
    "    store_url = f'{base_url}lat={lats[i]}&lon={lons[i]}&censusYear=2010&format=json'\n",
    "\n",
    "   # Run API request for each store\n",
    "    try:\n",
    "        # Store the results\n",
    "       results = requests.get(store_url).json()\n",
    "       \n",
    "       # Store the tract number - NOTE: only the first 11 digits because the API number is more specific than the Food Access Research Atlas\n",
    "       tract = results[\"results\"][0][\"block_fips\"][0:-4]\n",
    "\n",
    "        # Append the tract number to a list\n",
    "       census_tracts.append(tract)\n",
    "\n",
    "    except:\n",
    "       print(\"No tract available\")\n",
    "       pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the census tract numbers to integers\n",
    "census_tracts = [int(tract) for tract in census_tracts]\n",
    "\n",
    "# Store the census tracts with a McDonald's as a dataframe\n",
    "mctracts = pd.DataFrame(census_tracts, columns=[\"CensusTract\"])\n",
    "\n",
    "# Add a column to flag the census tracts\n",
    "mctracts[\"HasMcD\"] = 1\n",
    "\n",
    "# Group by the tract number\n",
    "mctracts_grp = mctracts.groupby(\"CensusTract\")\n",
    "\n",
    "# Using the grouped dataframe, create a column summing the flag column to show the number of McDonalds per census tract\n",
    "mctracts_num = pd.DataFrame(mctracts.groupby(\"CensusTract\")[\"HasMcD\"].sum())\n",
    "\n",
    "# Drop the duplicates in the original dataframe\n",
    "mctracts = mctracts.drop_duplicates(\"CensusTract\")\n",
    "\n",
    "# Merge the original dataframe to the one with a count column, in order to have both a flag and a count column\n",
    "mctracts_final = pd.merge(mctracts,mctracts_num,on=\"CensusTract\")\n",
    "\n",
    "# Rename the columns\n",
    "mctracts_final = mctracts_final.rename(columns = {\"HasMcD_x\":\"HasMcD\",\"HasMcD_y\":\"CountMcD\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the McDonald's count and flag columns onto the original FARA data\n",
    "tx_tracts = texas.merge(mctracts_final,how=\"left\", on=\"CensusTract\")\n",
    "\n",
    "# Replace the null values with zeros that represent no McDonald's in that census tract\n",
    "tx_tracts[[\"HasMcD\",\"CountMcD\"]] = tx_tracts[[\"HasMcD\",\"CountMcD\"]].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pandas dataframe to a sqlite file using sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "# Create an engine connection to the sqlite database\n",
    "conn = sqlite3.connect('../database/outputdata.sqlite')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5238"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covert the dataframe to sql\n",
    "tx_tracts.to_sql('dataframe', conn, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6034a9e124f3c20e2367bd866986b1fdd15cd81747522b9f323492d284f05081"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
